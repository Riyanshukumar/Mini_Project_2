{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6674c2f9-fe21-4dd2-ab10-e5d9c9e24eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded f10 class means for Task 2.\n",
      "Task 2: After processing task_two_Dataset D1, Accuracy Matrix Row 0: [0.8924 0.8928 0.8944 0.8964 0.892  0.898  0.8948 0.8948 0.8936 0.8964]\n",
      "Task 2: After processing task_two_Dataset D2, Accuracy Matrix Row 1: [0.8972 0.8988 0.898  0.8956 0.8988 0.9012 0.8992 0.896  0.8992 0.8988\n",
      " 0.7136]\n",
      "Task 2: After processing task_two_Dataset D3, Accuracy Matrix Row 2: [0.8988 0.8984 0.9004 0.8988 0.9    0.902  0.9012 0.8952 0.9    0.898\n",
      " 0.7128 0.5936]\n",
      "Task 2: After processing task_two_Dataset D4, Accuracy Matrix Row 3: [0.896  0.8968 0.8988 0.8988 0.8996 0.9032 0.8992 0.8964 0.8996 0.8988\n",
      " 0.7112 0.5848 0.7724]\n",
      "Task 2: After processing task_two_Dataset D5, Accuracy Matrix Row 4: [0.8936 0.8964 0.8968 0.8976 0.8964 0.9    0.9004 0.8948 0.8992 0.9\n",
      " 0.7064 0.574  0.7652 0.812 ]\n",
      "Task 2: After processing task_two_Dataset D6, Accuracy Matrix Row 5: [0.8968 0.8988 0.8992 0.8992 0.8996 0.8988 0.902  0.8964 0.8996 0.8988\n",
      " 0.7096 0.578  0.7744 0.8136 0.8712]\n",
      "Task 2: After processing task_two_Dataset D7, Accuracy Matrix Row 6: [0.8996 0.9016 0.9008 0.904  0.9052 0.9044 0.9052 0.9016 0.9024 0.9028\n",
      " 0.7132 0.5808 0.7784 0.8196 0.8748 0.7644]\n",
      "Task 2: After processing task_two_Dataset D8, Accuracy Matrix Row 7: [0.9032 0.9012 0.9024 0.9    0.9028 0.904  0.9056 0.8992 0.902  0.9036\n",
      " 0.7148 0.5912 0.7812 0.8196 0.8756 0.762  0.6784]\n",
      "Task 2: After processing task_two_Dataset D9, Accuracy Matrix Row 8: [0.8976 0.8976 0.9008 0.8972 0.8988 0.9028 0.9024 0.8964 0.8964 0.8964\n",
      " 0.7092 0.5844 0.7708 0.8148 0.8716 0.7556 0.6736 0.7324]\n",
      "Task 2: After processing task_two_Dataset D10, Accuracy Matrix Row 9: [0.8952 0.898  0.8992 0.8984 0.8992 0.9012 0.9016 0.8944 0.898  0.8996\n",
      " 0.7112 0.5756 0.7668 0.814  0.8716 0.7536 0.668  0.728  0.6812]\n",
      "Accuracy Matrix for Task 2:\n",
      "[[0.8924 0.8928 0.8944 0.8964 0.892  0.898  0.8948 0.8948 0.8936 0.8964\n",
      "  0.6988 0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8972 0.8988 0.898  0.8956 0.8988 0.9012 0.8992 0.896  0.8992 0.8988\n",
      "  0.7136 0.5972 0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8988 0.8984 0.9004 0.8988 0.9    0.902  0.9012 0.8952 0.9    0.898\n",
      "  0.7128 0.5936 0.7764 0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.896  0.8968 0.8988 0.8988 0.8996 0.9032 0.8992 0.8964 0.8996 0.8988\n",
      "  0.7112 0.5848 0.7724 0.8152 0.     0.     0.     0.     0.     0.    ]\n",
      " [0.8936 0.8964 0.8968 0.8976 0.8964 0.9    0.9004 0.8948 0.8992 0.9\n",
      "  0.7064 0.574  0.7652 0.812  0.872  0.     0.     0.     0.     0.    ]\n",
      " [0.8968 0.8988 0.8992 0.8992 0.8996 0.8988 0.902  0.8964 0.8996 0.8988\n",
      "  0.7096 0.578  0.7744 0.8136 0.8712 0.7596 0.     0.     0.     0.    ]\n",
      " [0.8996 0.9016 0.9008 0.904  0.9052 0.9044 0.9052 0.9016 0.9024 0.9028\n",
      "  0.7132 0.5808 0.7784 0.8196 0.8748 0.7644 0.6764 0.     0.     0.    ]\n",
      " [0.9032 0.9012 0.9024 0.9    0.9028 0.904  0.9056 0.8992 0.902  0.9036\n",
      "  0.7148 0.5912 0.7812 0.8196 0.8756 0.762  0.6784 0.7404 0.     0.    ]\n",
      " [0.8976 0.8976 0.9008 0.8972 0.8988 0.9028 0.9024 0.8964 0.8964 0.8964\n",
      "  0.7092 0.5844 0.7708 0.8148 0.8716 0.7556 0.6736 0.7324 0.6924 0.    ]\n",
      " [0.8952 0.898  0.8992 0.8984 0.8992 0.9012 0.9016 0.8944 0.898  0.8996\n",
      "  0.7112 0.5756 0.7668 0.814  0.8716 0.7536 0.668  0.728  0.6812 0.8064]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Pseudo-labeling with confidence\n",
    "def assign_pseudo_labels_with_confidence(features, class_means):\n",
    "    distances = cdist(features, class_means, metric='euclidean')  # Compute distance to each class mean\n",
    "    closest_class_indices = np.argmin(distances, axis=1)  # Assign to closest class\n",
    "    closest_distances = distances[np.arange(len(distances)), closest_class_indices]\n",
    "    total_distances = distances.sum(axis=1)\n",
    "\n",
    "    # Confidence: Inverse of normalized closest distance\n",
    "    confidences = 1 - (closest_distances / total_distances)\n",
    "    return closest_class_indices, confidences\n",
    "\n",
    "# Compute class statistics\n",
    "def compute_class_statistics(features, labels):\n",
    "    class_means = []\n",
    "    for cls in np.unique(labels):\n",
    "        cls_features = features[labels == cls]\n",
    "        mean = np.mean(cls_features, axis=0)\n",
    "        class_means.append(mean)\n",
    "    return np.array(class_means)\n",
    "\n",
    "# Update memory buffer\n",
    "def update_memory_buffer(memory_buffer, features, labels, budget=100):\n",
    "    \"\"\"Update memory buffer with representative samples.\"\"\"\n",
    "    new_samples = list(zip(features, labels))\n",
    "    memory_buffer.extend(new_samples)\n",
    "    if len(memory_buffer) > budget:\n",
    "        memory_buffer = memory_buffer[:budget]  # Trim to budget size\n",
    "    return memory_buffer\n",
    "\n",
    "# Consolidate class means\n",
    "def consolidate_internal_distribution(class_means_old, class_means_new, alpha=0.5):\n",
    "    \"\"\"Blend old and new class means using exponential moving average.\"\"\"\n",
    "    consolidated_means = []\n",
    "    for i in range(len(class_means_new)):\n",
    "        if i < len(class_means_old):\n",
    "            consolidated_mean = alpha * class_means_old[i] + (1 - alpha) * class_means_new[i]\n",
    "        else:\n",
    "            consolidated_mean = class_means_new[i]\n",
    "        consolidated_means.append(consolidated_mean)\n",
    "    return np.array(consolidated_means)\n",
    "\n",
    "# Load precomputed features\n",
    "def load_precomputed_features(dataset_type, dataset_index):\n",
    "    features_file = f\"extracted_feature/part_two_dataset/{dataset_type}/D{dataset_index}_{dataset_type}_features.npy\"\n",
    "    features = np.load(features_file)\n",
    "    return features\n",
    "\n",
    "# Task 2: Training and evaluation\n",
    "def task_two_model(initial_class_means, confidence_threshold=0.9):\n",
    "    class_means = initial_class_means\n",
    "    memory_buffer = []  # Memory buffer for representative samples\n",
    "    accuracies = np.zeros((10, 20))  # 10 rows for d1-d10, 20 columns for held-out datasets (D1-D20)\n",
    "\n",
    "    # Load features for Task 1 evaluation datasets (D1-D10)\n",
    "    task1_eval_features = []\n",
    "    for j in range(1, 11):  # D1 to D10\n",
    "        eval_features = np.load(f\"extracted_feature/part_one_dataset/eval/D{j}_eval_features.npy\")\n",
    "        task1_eval_features.append(eval_features)\n",
    "\n",
    "    # Load features for Task 2 datasets (d1-d10)\n",
    "    task2_train_features = []\n",
    "    task2_eval_features = []\n",
    "    for i in range(1, 11):  # d1 to d10\n",
    "        # Load training dataset features\n",
    "        train_features = load_precomputed_features(\"train\", i)\n",
    "        task2_train_features.append(train_features)\n",
    "\n",
    "        # Load evaluation dataset features\n",
    "        eval_features = load_precomputed_features(\"eval\", i)\n",
    "        task2_eval_features.append(eval_features)\n",
    "\n",
    "    # Training on Task 2 datasets\n",
    "    for i in range(1, 11):  # d1 to d10\n",
    "        X_di_features = task2_train_features[i - 1]\n",
    "\n",
    "        # Generate pseudo-labels with confidence\n",
    "        pseudo_labels, confidences = assign_pseudo_labels_with_confidence(X_di_features, class_means)\n",
    "\n",
    "        # Filter high-confidence samples\n",
    "        high_confidence_mask = confidences >= confidence_threshold\n",
    "        X_di_features = X_di_features[high_confidence_mask]\n",
    "        pseudo_labels = pseudo_labels[high_confidence_mask]\n",
    "\n",
    "        # Update class means\n",
    "        updated_means = compute_class_statistics(X_di_features, pseudo_labels)\n",
    "        class_means = consolidate_internal_distribution(class_means, updated_means)\n",
    "\n",
    "        # Update memory buffer\n",
    "        memory_buffer = update_memory_buffer(memory_buffer, X_di_features, pseudo_labels, budget=100)\n",
    "\n",
    "        # Evaluate on Task 1 datasets (D1-D10)\n",
    "        for j in range(1, 11):  # D1 to D10\n",
    "            X_eval_features = task1_eval_features[j - 1]\n",
    "            predictions, _ = assign_pseudo_labels_with_confidence(X_eval_features, class_means)\n",
    "\n",
    "            # If evaluation labels are known for testing purposes, compute accuracy\n",
    "            eval_labels_file = f\"extracted_feature/part_one_dataset/eval/D{j}_eval_labels.npy\"\n",
    "            if os.path.exists(eval_labels_file):\n",
    "                y_eval = np.load(eval_labels_file)\n",
    "                accuracies[i - 1, j - 1] = accuracy_score(y_eval, predictions)\n",
    "\n",
    "        # Evaluate on Task 2 datasets (d1-di)\n",
    "        for j in range(1, i + 1):  # d1 to di\n",
    "            X_eval_features = task2_eval_features[j - 1]\n",
    "            predictions, _ = assign_pseudo_labels_with_confidence(X_eval_features, class_means)\n",
    "\n",
    "            # If evaluation labels are known for testing purposes, compute accuracy\n",
    "            eval_labels_file = f\"extracted_feature/part_two_dataset/eval/D{j}_eval_labels.npy\"\n",
    "            if os.path.exists(eval_labels_file):\n",
    "                y_eval = np.load(eval_labels_file)\n",
    "                accuracies[i - 1, j + 9] = accuracy_score(y_eval, predictions)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Task 2: After processing task_two_Dataset D{i}, Accuracy Matrix Row {i - 1}: {accuracies[i - 1, :i + 9]}\")\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the initial class means from Task 1\n",
    "    initial_class_means = torch.load('f10_class_means_task1.npy')\n",
    "    print(\"Loaded f10 class means for Task 2.\")\n",
    "\n",
    "    # Task 2: Proceed with d1-d10\n",
    "    accuracies_task_2 = task_two_model(initial_class_means, confidence_threshold=0.9)\n",
    "\n",
    "    print(\"Accuracy Matrix for Task 2:\")\n",
    "    print(accuracies_task_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e17071-fe41-4df8-8d06-b4e4d3a08709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
